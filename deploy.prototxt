name: "AlexNet"
layer {
  name: "data"
  type: "Input"
  top: "data"
  input_param { 
    shape: { 
    dim: 1 
    dim: 3 
    dim: 228 
    dim: 228 
    } 
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  convolution_param {
    num_output: 48
    kernel_size: 9
    stride: 4
  }
}
layer {
 bottom: "conv1"
 top: "conv1"
 name: "bn_conv1"
 type: "BatchNorm"
 batch_norm_param {
  use_global_stats: true
 }
}

layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
  }
}

layer {
 bottom: "conv2"
 top: "conv2"
 name: "bn_conv2"
 type: "BatchNorm"
 batch_norm_param {
  use_global_stats: true
 }
}

layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "conv2"
  top: "conv3"
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
  }
}

layer {
 bottom: "conv3"
 top: "conv3"
 name: "bn_conv3"
 type: "BatchNorm"
 batch_norm_param {
  use_global_stats: true
 }
}

layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}

layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv3"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}

layer {
  name: "conv4"
  type: "Convolution"
  bottom: "pool2"
  top: "conv4"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
  }
}

layer {
 bottom: "conv4"
 top: "conv4"
 name: "bn_conv4"
 type: "BatchNorm"
 batch_norm_param {
  use_global_stats: true
 }
}

layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "conv5"
  type: "Convolution"
  bottom: "conv4"
  top: "conv5"
  convolution_param {
    num_output: 192
    pad: 1
    kernel_size: 3
  }
}

layer {
 bottom: "conv5"
 top: "conv5"
 name: "bn_conv5"
 type: "BatchNorm"
 batch_norm_param {
  use_global_stats: true
 }
}

layer {
  name: "relu5"
  type: "ReLU"
  bottom: "conv5"
  top: "conv5"
}

layer {
  name: "conv6"
  type: "Convolution"
  bottom: "conv5"
  top: "conv6"
  convolution_param {
    num_output: 192
    pad: 1
    kernel_size: 3
  }
}

layer {
 bottom: "conv6"
 top: "conv6"
 name: "bn_conv6"
 type: "BatchNorm"
 batch_norm_param {
  use_global_stats: true
 }
}

layer {
  name: "relu6"
  type: "ReLU"
  bottom: "conv6"
  top: "conv6"
}

layer {
  name: "conv7"
  type: "Convolution"
  bottom: "conv6"
  top: "conv7"
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
  }
}

layer {
 bottom: "conv7"
 top: "conv7"
 name: "bn_conv7"
 type: "BatchNorm"
 batch_norm_param {
  use_global_stats: true
 }
}

layer {
  name: "relu7"
  type: "ReLU"
  bottom: "conv7"
  top: "conv7"
}

layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv7"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "fc1"
  type: "InnerProduct"
  bottom: "pool3"
  top: "fc1"
  inner_product_param {
    num_output: 4096
  }
}

layer {
 bottom: "fc1"
 top: "fc1"
 name: "bn_fc1"
 type: "BatchNorm"
 batch_norm_param {
  use_global_stats: true
 }
}

layer {
  name: "relu-fc1"
  type: "ReLU"
  bottom: "fc1"
  top: "fc1"
}
layer {
  name: "fc2"
  type: "InnerProduct"
  bottom: "fc1"
  top: "fc2"
  inner_product_param {
    num_output: 2048
  }
}

###bellow not sure???
layer {
 bottom: "fc2"
 top: "fc2"
 name: "bn_fc2"
 type: "BatchNorm"
 batch_norm_param {
  use_global_stats: true
 }
}

layer {
  name: "relu-fc2"
  type: "ReLU"
  bottom: "fc2"
  top: "fc2"
}
